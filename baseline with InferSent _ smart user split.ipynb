{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frizman04\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "import pickle \n",
    "\n",
    "import matplotlib\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "GLOVE_PATH = 'InferSent/glove.840B.300d.txt'\n",
    "INFERSENT_MODEL_PATH = 'InferSent/infersent.allnli.pickle'\n",
    "MODEL_PATH = 'model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/dataset_cleanup.json') as file :\n",
    "    dataset  = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "Y = [] #is conversation with bot\n",
    "X_df = pd.DataFrame(columns=['dialog_indx','is_user1','is_user2','text','embeding'])\n",
    "X_tmp = []\n",
    "\n",
    "for indx,sample in enumerate(dataset) :\n",
    "    \n",
    "    user1_id = sample['thread'][0]['userId'] #будим считать первым того user который начал диалог\n",
    "    \n",
    "    users_id = np.array([user['id'] for user in sample['users']])\n",
    "    user2_id = users_id[users_id != user1_id][0]\n",
    "    \n",
    "    usersid_2_isbot_list = {user['id'] : 'Bot' in user['userType'] for user in sample['users']}    \n",
    "    \n",
    "    y = [int(usersid_2_isbot_list[user1_id]),int(usersid_2_isbot_list[user2_id])]\n",
    "        \n",
    "    Y.append(y)\n",
    "    \n",
    "    for phraze in sample['thread'] :\n",
    "        is_user1 = int(phraze['userId'] == user1_id)\n",
    "        is_user2 = int(phraze['userId'] == user2_id) #если сказал 2й юзер то Ture. если 1й то False\n",
    "        X_tmp.append([indx,is_user1,is_user2,phraze['text']])\n",
    "\n",
    "X_tmp = np.array(X_tmp)      \n",
    "X_df['dialog_indx'] = X_tmp[:,0]\n",
    "X_df['is_user1'] = X_tmp[:,1]\n",
    "X_df['is_user2'] = X_tmp[:,2]\n",
    "X_df['text'] = X_tmp[:,3]\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_df['dialog_indx'] = X_df['dialog_indx'].apply(pd.to_numeric)\n",
    "X_df['is_user1'] = X_df['is_user1'].apply(pd.to_numeric)\n",
    "X_df['is_user2'] = X_df['is_user2'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialog_indx</th>\n",
       "      <th>is_user1</th>\n",
       "      <th>is_user2</th>\n",
       "      <th>text</th>\n",
       "      <th>embeding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>What is the text about?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>High-definition image sources</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Blu-ray video disc?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Never heard about Roku boxes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dialog_indx  is_user1  is_user2                           text embeding\n",
       "0            0         1         0                              f      NaN\n",
       "1            0         0         1        What is the text about?      NaN\n",
       "2            0         1         0  High-definition image sources      NaN\n",
       "3            0         1         0            Blu-ray video disc?      NaN\n",
       "4            0         0         1   Never heard about Roku boxes      NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y : (2759, 2) \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-a4484485274d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Y : %s '\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'len_X : %s '\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'X_text[0] : %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mX_text\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_text' is not defined"
     ]
    }
   ],
   "source": [
    "print('Y : %s ' % str(Y.shape))\n",
    "print('len_X : %s ' % len(X_text))\n",
    "print('X_text[0] : %s' % X_text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create sent embedings with InferSent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frizman04\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:325: SourceChangeWarning: source code of class 'models.BLSTMEncoder' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\frizman04\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:325: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.LSTM' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size : 100000\n",
      "Wall time: 24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_inferSent = torch.load(INFERSENT_MODEL_PATH, map_location=lambda storage, loc: storage)\n",
    "torch.set_num_threads(5)\n",
    "\n",
    "model_inferSent.set_glove_path(GLOVE_PATH)\n",
    "model_inferSent.build_vocab_k_words(K=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb words kept : 236938/281054 (84.3 %)\n",
      "Speed : 50.82 sentences/s (cpu mode, bsize=128)\n",
      "Wall time: 11min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embedings = model_inferSent.encode(X_df['text'].values, bsize=128, tokenize=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMPTY_INFERSENT_VECT = np.zeros(shape=4096) #model_inferSent.encode([''])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for indx,embd in enumerate(embedings) :\n",
    "    X_df.at[indx,'embeding'] = embd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialog_indx</th>\n",
       "      <th>is_user1</th>\n",
       "      <th>is_user2</th>\n",
       "      <th>text</th>\n",
       "      <th>embeding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>[0.011967509, -0.06771015, -0.014055675, -0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>What is the text about?</td>\n",
       "      <td>[0.0711433, 0.054118324, 0.04687867, -0.073211...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>High-definition image sources</td>\n",
       "      <td>[0.07495881, 0.058115814, 0.08857289, -0.06326...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Blu-ray video disc?</td>\n",
       "      <td>[0.091638826, 0.03246896, -0.026797447, 0.0587...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Never heard about Roku boxes</td>\n",
       "      <td>[0.03827866, 0.04058365, 0.004118561, 0.012654...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dialog_indx  is_user1  is_user2                           text  \\\n",
       "0            0         1         0                              f   \n",
       "1            0         0         1        What is the text about?   \n",
       "2            0         1         0  High-definition image sources   \n",
       "3            0         1         0            Blu-ray video disc?   \n",
       "4            0         0         1   Never heard about Roku boxes   \n",
       "\n",
       "                                            embeding  \n",
       "0  [0.011967509, -0.06771015, -0.014055675, -0.08...  \n",
       "1  [0.0711433, 0.054118324, 0.04687867, -0.073211...  \n",
       "2  [0.07495881, 0.058115814, 0.08857289, -0.06326...  \n",
       "3  [0.091638826, 0.03246896, -0.026797447, 0.0587...  \n",
       "4  [0.03827866, 0.04058365, 0.004118561, 0.012654...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COUNT_OF_DIALOG = X_df['dialog_indx'].max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max dialog len : 34 \n"
     ]
    }
   ],
   "source": [
    "MAX_DIALOG_LENGTH = -100\n",
    "\n",
    "for indx in range(COUNT_OF_DIALOG) :\n",
    "    curr_dialg_len = len(X_df.loc[X_df['dialog_indx'] == indx]['dialog_indx'].values)\n",
    "    if curr_dialg_len > MAX_DIALOG_LENGTH :\n",
    "        MAX_DIALOG_LENGTH = curr_dialg_len\n",
    "\n",
    "print('Max dialog len : %s ' % MAX_DIALOG_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X = []\n",
    "EMPTY_INFERSENT_VECT_with_user1or2 = np.hstack(([0,0],EMPTY_INFERSENT_VECT))\n",
    "\n",
    "for indx in range(COUNT_OF_DIALOG) :\n",
    "    \n",
    "    curr_dialog_embeding = list(X_df.loc[X_df['dialog_indx'] == indx]['embeding'].values)\n",
    "    curr_dialog_user1or2 = X_df.loc[X_df['dialog_indx'] == indx][['is_user1','is_user2']].values\n",
    "\n",
    "    curr_dialog = []\n",
    "    for embeding,user1or2 in zip(curr_dialog_embeding,curr_dialog_user1or2) :\n",
    "        curr_dialog.append(np.hstack((user1or2,embeding)))\n",
    "    \n",
    "    while len(curr_dialog) < MAX_DIALOG_LENGTH :\n",
    "        curr_dialog.append(EMPTY_INFERSENT_VECT_with_user1or2)\n",
    "    curr_dialog = np.array(curr_dialog)\n",
    "    X.append(curr_dialog)\n",
    "    \n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape (2759, 34, 4098) \n"
     ]
    }
   ],
   "source": [
    "print('X shape %s ' % str(X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.save(open('tmp/X_InferSent_with_user_marker_empty0','wb'),X)\n",
    "#np.save(open('tmp/Y_InferSent_v2','wb'),Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.load(open('tmp/X_InferSent_with_user_marker_empty0','rb'))\n",
    "Y = np.load(open('tmp/Y_InferSent_v2','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore class balans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First bots part : 0.5059804276911924\n",
      "Second bots part : 0.35773831098223996\n"
     ]
    }
   ],
   "source": [
    "print('First bots part : %s' % np.average(Y[:,0]))\n",
    "print('Second bots part : %s' % np.average(Y[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert dataset to indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (2207, 34, 4098)\n",
      "X_test shape (552, 34, 4098)\n",
      "y_train shape (2207, 2)\n",
      "y_test shape (552, 2)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape %s' % str(X_train.shape))\n",
    "print('X_test shape %s' % str(X_test.shape))\n",
    "\n",
    "print('y_train shape %s' % str(y_train.shape))\n",
    "print('y_test shape %s' % str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lstm_cell(lstm_hiden_units, keep_prob):\n",
    "    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units=lstm_hiden_units, activation=tf.tanh)\n",
    "    drop = tf.nn.rnn_cell.DropoutWrapper(lstm_cell, output_keep_prob=keep_prob)\n",
    "    return drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"logits/Sigmoid:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "lstm_hiden_units = 32\n",
    "#lstm_layers = 1\n",
    "#keep_prob = 1\n",
    "embeding_size = 4096 + 2\n",
    "\n",
    "input_vect = tf.placeholder(tf.float32,shape=[None,None,embeding_size],name='input_vect')\n",
    "input_y = tf.placeholder(tf.float32, shape=[None,2], name='input_y')\n",
    "sequence_length = tf.placeholder(tf.float32, shape=[None], name='seq_length')\n",
    "\n",
    "\n",
    "#rnn = tf.nn.rnn_cell.MultiRNNCell([get_lstm_cell(lstm_hiden_units,keep_prob) for _ in range(lstm_layers) ])\n",
    "\n",
    "lstm = tf.nn.rnn_cell.BasicLSTMCell(num_units=lstm_hiden_units, activation=tf.tanh)\n",
    "lstm_outputs, states = tf.nn.dynamic_rnn(lstm, input_vect,sequence_length = sequence_length, dtype=tf.float32)\n",
    "\n",
    "#flatten = tf.reshape(lstm_outputs,shape=[-1,MAX_DIALOG_LENGTH*lstm_hiden_units],name='flatten')\n",
    "\n",
    "dense_layer = tf.layers.dense(inputs=states.c,\n",
    "                              units=64,\n",
    "                              activation=tf.nn.relu,\n",
    "                              kernel_initializer = tf.glorot_normal_initializer(), #tf.initializers.identity(gain=0.5)\n",
    "                              kernel_regularizer = tf.contrib.layers.l2_regularizer(scale=1.0),\n",
    "                              name='dense_layer')\n",
    "\n",
    "logits = tf.layers.dense(dense_layer,\n",
    "                         units=2,\n",
    "                         kernel_initializer = tf.glorot_normal_initializer(),\n",
    "                         activation = tf.nn.sigmoid,\n",
    "                         name='logits')\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_seq_len(X) :\n",
    "    return np.sum(X.sum(axis=2) != 0,axis=1)\n",
    "\n",
    "def get_next_batch(X,Y,batch_size,batch_indx) :\n",
    "    '''\n",
    "    Iterate over batches.\n",
    "        return X_batch,y_bath,seq_length_inbatch\n",
    "    \n",
    "    '''\n",
    "    left_bound = batch_indx*batch_size\n",
    "    right_bound = (batch_indx + 1)*batch_size\n",
    "    if right_bound > X.shape[0] :\n",
    "        right_bound = X.shape[0]\n",
    "    \n",
    "    X_batch = X[left_bound:right_bound,:]\n",
    "    Y_batch = Y[left_bound:right_bound,:]\n",
    "    seq_length = get_seq_len(X_batch)\n",
    "    return (X_batch,Y_batch,seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=input_y, logits = logits)\n",
    "\n",
    "lr = tf.placeholder(dtype=tf.float32,shape=None)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_epoch : 0, train_loss : 0.5387866\n",
      "current_epoch : 0, train_loss : 0.538787, test_loss : 0.577713, train_auc : 0.99364, test_auc : 0.95435, test_acc : 0.89062 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frizman04\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:1128: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "C:\\Users\\frizman04\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_epoch : 1, train_loss : 0.5344663\n",
      "current_epoch : 2, train_loss : 0.53407097\n",
      "current_epoch : 3, train_loss : 0.5334981\n",
      "current_epoch : 4, train_loss : 0.5334687\n",
      "current_epoch : 5, train_loss : 0.5332824\n",
      "current_epoch : 6, train_loss : 0.53323996\n",
      "current_epoch : 7, train_loss : 0.53322375\n",
      "current_epoch : 8, train_loss : 0.53319985\n",
      "current_epoch : 9, train_loss : 0.5331813\n",
      "current_epoch : 10, train_loss : 0.5331653\n",
      "current_epoch : 10, train_loss : 0.533165, test_loss : 0.578755, train_auc : 0.99416, test_auc : 0.95607, test_acc : 0.89453 \n",
      "current_epoch : 11, train_loss : 0.53314954\n",
      "current_epoch : 12, train_loss : 0.5331347\n",
      "current_epoch : 13, train_loss : 0.53312135\n",
      "current_epoch : 14, train_loss : 0.53310955\n",
      "current_epoch : 15, train_loss : 0.53309906\n",
      "current_epoch : 16, train_loss : 0.53308964\n",
      "current_epoch : 17, train_loss : 0.5330811\n",
      "current_epoch : 18, train_loss : 0.53307325\n",
      "current_epoch : 19, train_loss : 0.5330661\n",
      "current_epoch : 20, train_loss : 0.5330594\n",
      "current_epoch : 20, train_loss : 0.533059, test_loss : 0.579260, train_auc : 0.99424, test_auc : 0.95570, test_acc : 0.89160 \n",
      "current_epoch : 21, train_loss : 0.5330531\n",
      "current_epoch : 22, train_loss : 0.5330473\n",
      "current_epoch : 23, train_loss : 0.53304183\n",
      "current_epoch : 24, train_loss : 0.5330367\n",
      "current_epoch : 25, train_loss : 0.533032\n",
      "current_epoch : 26, train_loss : 0.5330275\n",
      "current_epoch : 27, train_loss : 0.53302336\n",
      "current_epoch : 28, train_loss : 0.53301954\n",
      "current_epoch : 29, train_loss : 0.53301597\n",
      "current_epoch : 30, train_loss : 0.53301275\n",
      "current_epoch : 30, train_loss : 0.533013, test_loss : 0.579616, train_auc : 0.99425, test_auc : 0.95556, test_acc : 0.89062 \n",
      "current_epoch : 31, train_loss : 0.5330096\n",
      "current_epoch : 32, train_loss : 0.5330067\n",
      "current_epoch : 33, train_loss : 0.53300405\n",
      "current_epoch : 34, train_loss : 0.5330016\n",
      "current_epoch : 35, train_loss : 0.5329993\n",
      "current_epoch : 36, train_loss : 0.5329971\n",
      "current_epoch : 37, train_loss : 0.53299505\n",
      "current_epoch : 38, train_loss : 0.5329931\n",
      "current_epoch : 39, train_loss : 0.5329913\n",
      "current_epoch : 40, train_loss : 0.5329895\n",
      "current_epoch : 40, train_loss : 0.532990, test_loss : 0.579720, train_auc : 0.99426, test_auc : 0.95548, test_acc : 0.88965 \n",
      "current_epoch : 41, train_loss : 0.53298783\n",
      "current_epoch : 42, train_loss : 0.5329863\n",
      "current_epoch : 43, train_loss : 0.53298485\n",
      "current_epoch : 44, train_loss : 0.53298336\n",
      "current_epoch : 45, train_loss : 0.53298205\n",
      "current_epoch : 46, train_loss : 0.53298074\n",
      "current_epoch : 47, train_loss : 0.53297955\n",
      "current_epoch : 48, train_loss : 0.5329783\n",
      "current_epoch : 49, train_loss : 0.5329771\n",
      "current_epoch : 50, train_loss : 0.53297603\n",
      "current_epoch : 50, train_loss : 0.532976, test_loss : 0.579749, train_auc : 0.99408, test_auc : 0.95530, test_acc : 0.88965 \n",
      "current_epoch : 51, train_loss : 0.53297496\n",
      "current_epoch : 52, train_loss : 0.5329739\n",
      "current_epoch : 53, train_loss : 0.53297293\n",
      "current_epoch : 54, train_loss : 0.532972\n",
      "current_epoch : 55, train_loss : 0.532971\n",
      "current_epoch : 56, train_loss : 0.5329701\n",
      "current_epoch : 57, train_loss : 0.5329692\n",
      "current_epoch : 58, train_loss : 0.53296834\n",
      "current_epoch : 59, train_loss : 0.53296745\n",
      "current_epoch : 60, train_loss : 0.53296673\n",
      "current_epoch : 60, train_loss : 0.532967, test_loss : 0.579763, train_auc : 0.99408, test_auc : 0.95529, test_acc : 0.88965 \n",
      "current_epoch : 61, train_loss : 0.5329659\n",
      "current_epoch : 62, train_loss : 0.5329651\n",
      "current_epoch : 63, train_loss : 0.53296435\n",
      "current_epoch : 64, train_loss : 0.53296363\n",
      "current_epoch : 65, train_loss : 0.5329629\n",
      "current_epoch : 66, train_loss : 0.5329622\n",
      "current_epoch : 67, train_loss : 0.5329615\n",
      "current_epoch : 68, train_loss : 0.5329609\n",
      "current_epoch : 69, train_loss : 0.5329602\n",
      "current_epoch : 70, train_loss : 0.53295946\n",
      "current_epoch : 70, train_loss : 0.532959, test_loss : 0.579759, train_auc : 0.99407, test_auc : 0.95528, test_acc : 0.88867 \n",
      "current_epoch : 71, train_loss : 0.53295887\n",
      "current_epoch : 72, train_loss : 0.53295827\n",
      "current_epoch : 73, train_loss : 0.5329577\n",
      "current_epoch : 74, train_loss : 0.5329571\n",
      "current_epoch : 75, train_loss : 0.5329565\n",
      "current_epoch : 76, train_loss : 0.5329559\n",
      "current_epoch : 77, train_loss : 0.53295535\n",
      "current_epoch : 78, train_loss : 0.5329548\n",
      "current_epoch : 79, train_loss : 0.5329542\n",
      "current_epoch : 80, train_loss : 0.5329536\n",
      "current_epoch : 80, train_loss : 0.532954, test_loss : 0.579748, train_auc : 0.99408, test_auc : 0.95530, test_acc : 0.88867 \n",
      "current_epoch : 81, train_loss : 0.53295314\n",
      "current_epoch : 82, train_loss : 0.5329526\n",
      "current_epoch : 83, train_loss : 0.5329521\n",
      "current_epoch : 84, train_loss : 0.53295153\n",
      "current_epoch : 85, train_loss : 0.5329511\n",
      "current_epoch : 86, train_loss : 0.5329506\n",
      "current_epoch : 87, train_loss : 0.5329501\n",
      "current_epoch : 88, train_loss : 0.5329496\n",
      "current_epoch : 89, train_loss : 0.53294915\n",
      "current_epoch : 90, train_loss : 0.53294873\n",
      "current_epoch : 90, train_loss : 0.532949, test_loss : 0.579735, train_auc : 0.99407, test_auc : 0.95514, test_acc : 0.88867 \n",
      "current_epoch : 91, train_loss : 0.5329482\n",
      "current_epoch : 92, train_loss : 0.5329478\n",
      "current_epoch : 93, train_loss : 0.5329473\n",
      "current_epoch : 94, train_loss : 0.5329469\n",
      "current_epoch : 95, train_loss : 0.53294647\n",
      "current_epoch : 96, train_loss : 0.532946\n",
      "current_epoch : 97, train_loss : 0.53294563\n",
      "current_epoch : 98, train_loss : 0.53294516\n",
      "current_epoch : 99, train_loss : 0.53294474\n",
      "current_epoch : 100, train_loss : 0.5329443\n",
      "current_epoch : 100, train_loss : 0.532944, test_loss : 0.579712, train_auc : 0.99409, test_auc : 0.95486, test_acc : 0.88867 \n",
      "current_epoch : 101, train_loss : 0.53294396\n",
      "current_epoch : 102, train_loss : 0.5329435\n",
      "current_epoch : 103, train_loss : 0.5329431\n",
      "current_epoch : 104, train_loss : 0.5329428\n",
      "current_epoch : 105, train_loss : 0.53294235\n",
      "current_epoch : 106, train_loss : 0.532942\n",
      "current_epoch : 107, train_loss : 0.5329416\n",
      "current_epoch : 108, train_loss : 0.5329412\n",
      "current_epoch : 109, train_loss : 0.53294086\n",
      "current_epoch : 110, train_loss : 0.5329404\n",
      "current_epoch : 110, train_loss : 0.532940, test_loss : 0.579688, train_auc : 0.99410, test_auc : 0.95489, test_acc : 0.88867 \n",
      "current_epoch : 111, train_loss : 0.5329401\n",
      "current_epoch : 112, train_loss : 0.53293973\n",
      "current_epoch : 113, train_loss : 0.5329394\n",
      "current_epoch : 114, train_loss : 0.532939\n",
      "current_epoch : 115, train_loss : 0.53293866\n",
      "current_epoch : 116, train_loss : 0.5329383\n",
      "current_epoch : 117, train_loss : 0.53293794\n",
      "current_epoch : 118, train_loss : 0.53293765\n",
      "current_epoch : 119, train_loss : 0.5329373\n",
      "current_epoch : 120, train_loss : 0.53293693\n",
      "current_epoch : 120, train_loss : 0.532937, test_loss : 0.579663, train_auc : 0.99410, test_auc : 0.95485, test_acc : 0.88965 \n",
      "current_epoch : 121, train_loss : 0.5329366\n",
      "current_epoch : 122, train_loss : 0.53293633\n",
      "current_epoch : 123, train_loss : 0.532936\n",
      "current_epoch : 124, train_loss : 0.5329356\n",
      "current_epoch : 125, train_loss : 0.5329353\n",
      "current_epoch : 126, train_loss : 0.532935\n",
      "current_epoch : 127, train_loss : 0.53293467\n",
      "current_epoch : 128, train_loss : 0.53293437\n",
      "current_epoch : 129, train_loss : 0.53293407\n",
      "current_epoch : 130, train_loss : 0.53293383\n",
      "current_epoch : 130, train_loss : 0.532934, test_loss : 0.579640, train_auc : 0.99408, test_auc : 0.95486, test_acc : 0.88965 \n",
      "current_epoch : 131, train_loss : 0.5329335\n",
      "current_epoch : 132, train_loss : 0.5329332\n",
      "current_epoch : 133, train_loss : 0.5329328\n",
      "current_epoch : 134, train_loss : 0.5329325\n",
      "current_epoch : 135, train_loss : 0.5329323\n",
      "current_epoch : 136, train_loss : 0.532932\n",
      "current_epoch : 137, train_loss : 0.5329317\n",
      "current_epoch : 138, train_loss : 0.53293145\n",
      "current_epoch : 139, train_loss : 0.5329311\n",
      "current_epoch : 140, train_loss : 0.5329308\n",
      "current_epoch : 140, train_loss : 0.532931, test_loss : 0.579608, train_auc : 0.99409, test_auc : 0.95489, test_acc : 0.89062 \n",
      "current_epoch : 141, train_loss : 0.53293055\n",
      "current_epoch : 142, train_loss : 0.53293025\n",
      "current_epoch : 143, train_loss : 0.53293\n",
      "current_epoch : 144, train_loss : 0.5329297\n",
      "current_epoch : 145, train_loss : 0.5329295\n",
      "current_epoch : 146, train_loss : 0.5329292\n",
      "current_epoch : 147, train_loss : 0.53292894\n",
      "current_epoch : 148, train_loss : 0.53292865\n",
      "current_epoch : 149, train_loss : 0.5329284\n",
      "current_epoch : 150, train_loss : 0.5329281\n",
      "current_epoch : 150, train_loss : 0.532928, test_loss : 0.579572, train_auc : 0.99407, test_auc : 0.95488, test_acc : 0.89062 \n",
      "current_epoch : 151, train_loss : 0.5329279\n",
      "current_epoch : 152, train_loss : 0.53292763\n",
      "current_epoch : 153, train_loss : 0.5329274\n",
      "current_epoch : 154, train_loss : 0.53292716\n",
      "current_epoch : 155, train_loss : 0.5329268\n",
      "current_epoch : 156, train_loss : 0.53292656\n",
      "current_epoch : 157, train_loss : 0.5329263\n",
      "current_epoch : 158, train_loss : 0.5329261\n",
      "current_epoch : 159, train_loss : 0.53292584\n",
      "current_epoch : 160, train_loss : 0.5329256\n",
      "current_epoch : 160, train_loss : 0.532926, test_loss : 0.579530, train_auc : 0.99409, test_auc : 0.95488, test_acc : 0.89062 \n",
      "current_epoch : 161, train_loss : 0.53292537\n",
      "current_epoch : 162, train_loss : 0.5329252\n",
      "current_epoch : 163, train_loss : 0.5329249\n",
      "current_epoch : 164, train_loss : 0.53292465\n",
      "current_epoch : 165, train_loss : 0.5329244\n",
      "current_epoch : 166, train_loss : 0.5329242\n",
      "current_epoch : 167, train_loss : 0.53292394\n",
      "current_epoch : 168, train_loss : 0.53292376\n",
      "current_epoch : 169, train_loss : 0.53292346\n",
      "current_epoch : 170, train_loss : 0.5329233\n",
      "current_epoch : 170, train_loss : 0.532923, test_loss : 0.579487, train_auc : 0.99408, test_auc : 0.95493, test_acc : 0.89062 \n",
      "current_epoch : 171, train_loss : 0.532923\n",
      "current_epoch : 172, train_loss : 0.53292286\n",
      "current_epoch : 173, train_loss : 0.5329226\n",
      "current_epoch : 174, train_loss : 0.5329224\n",
      "current_epoch : 175, train_loss : 0.53292215\n",
      "current_epoch : 176, train_loss : 0.5329219\n",
      "current_epoch : 177, train_loss : 0.5329217\n",
      "current_epoch : 178, train_loss : 0.5329215\n",
      "current_epoch : 179, train_loss : 0.5329213\n",
      "current_epoch : 180, train_loss : 0.5329211\n",
      "current_epoch : 180, train_loss : 0.532921, test_loss : 0.579442, train_auc : 0.99409, test_auc : 0.95455, test_acc : 0.88965 \n",
      "current_epoch : 181, train_loss : 0.5329209\n",
      "current_epoch : 182, train_loss : 0.53292066\n",
      "current_epoch : 183, train_loss : 0.5329205\n",
      "current_epoch : 184, train_loss : 0.53292024\n",
      "current_epoch : 185, train_loss : 0.53292\n",
      "current_epoch : 186, train_loss : 0.5329198\n",
      "current_epoch : 187, train_loss : 0.53291965\n",
      "current_epoch : 188, train_loss : 0.5329194\n",
      "current_epoch : 189, train_loss : 0.5329192\n",
      "current_epoch : 190, train_loss : 0.53291905\n",
      "current_epoch : 190, train_loss : 0.532919, test_loss : 0.579392, train_auc : 0.99408, test_auc : 0.95458, test_acc : 0.88965 \n",
      "current_epoch : 191, train_loss : 0.5329188\n",
      "current_epoch : 192, train_loss : 0.53291863\n",
      "current_epoch : 193, train_loss : 0.53291845\n",
      "current_epoch : 194, train_loss : 0.5329182\n",
      "current_epoch : 195, train_loss : 0.53291804\n",
      "current_epoch : 196, train_loss : 0.53291786\n",
      "current_epoch : 197, train_loss : 0.5329177\n",
      "current_epoch : 198, train_loss : 0.5329175\n",
      "current_epoch : 199, train_loss : 0.53291726\n",
      "current_epoch : 200, train_loss : 0.5329171\n",
      "current_epoch : 200, train_loss : 0.532917, test_loss : 0.579342, train_auc : 0.99408, test_auc : 0.95378, test_acc : 0.88965 \n",
      "current_epoch : 201, train_loss : 0.5329169\n",
      "current_epoch : 202, train_loss : 0.5329167\n",
      "current_epoch : 203, train_loss : 0.53291655\n",
      "current_epoch : 204, train_loss : 0.5329163\n",
      "current_epoch : 205, train_loss : 0.5329162\n",
      "current_epoch : 206, train_loss : 0.53291595\n",
      "current_epoch : 207, train_loss : 0.53291583\n",
      "current_epoch : 208, train_loss : 0.5329156\n",
      "current_epoch : 209, train_loss : 0.5329155\n",
      "current_epoch : 210, train_loss : 0.53291523\n",
      "current_epoch : 210, train_loss : 0.532915, test_loss : 0.579289, train_auc : 0.99409, test_auc : 0.95371, test_acc : 0.88965 \n",
      "current_epoch : 211, train_loss : 0.5329151\n",
      "current_epoch : 212, train_loss : 0.53291494\n",
      "current_epoch : 213, train_loss : 0.53291476\n",
      "current_epoch : 214, train_loss : 0.5329145\n",
      "current_epoch : 215, train_loss : 0.5329144\n",
      "current_epoch : 216, train_loss : 0.5329142\n",
      "current_epoch : 217, train_loss : 0.53291404\n",
      "current_epoch : 218, train_loss : 0.53291386\n",
      "current_epoch : 219, train_loss : 0.5329137\n",
      "current_epoch : 220, train_loss : 0.5329135\n",
      "current_epoch : 220, train_loss : 0.532914, test_loss : 0.579236, train_auc : 0.99410, test_auc : 0.95348, test_acc : 0.88965 \n",
      "current_epoch : 221, train_loss : 0.5329133\n",
      "current_epoch : 222, train_loss : 0.5329132\n",
      "current_epoch : 223, train_loss : 0.53291297\n",
      "current_epoch : 224, train_loss : 0.53291285\n",
      "current_epoch : 225, train_loss : 0.5329127\n",
      "current_epoch : 226, train_loss : 0.5329125\n",
      "current_epoch : 227, train_loss : 0.5329124\n",
      "current_epoch : 228, train_loss : 0.53291214\n",
      "current_epoch : 229, train_loss : 0.532912\n",
      "current_epoch : 230, train_loss : 0.5329119\n",
      "current_epoch : 230, train_loss : 0.532912, test_loss : 0.579183, train_auc : 0.99408, test_auc : 0.95340, test_acc : 0.88965 \n",
      "current_epoch : 231, train_loss : 0.5329117\n",
      "current_epoch : 232, train_loss : 0.53291154\n",
      "current_epoch : 233, train_loss : 0.5329114\n",
      "current_epoch : 234, train_loss : 0.5329112\n",
      "current_epoch : 235, train_loss : 0.53291106\n",
      "current_epoch : 236, train_loss : 0.5329109\n",
      "current_epoch : 237, train_loss : 0.5329107\n",
      "current_epoch : 238, train_loss : 0.5329106\n",
      "current_epoch : 239, train_loss : 0.5329104\n",
      "current_epoch : 240, train_loss : 0.5329102\n",
      "current_epoch : 240, train_loss : 0.532910, test_loss : 0.579130, train_auc : 0.99408, test_auc : 0.95348, test_acc : 0.88965 \n",
      "current_epoch : 241, train_loss : 0.5329101\n",
      "current_epoch : 242, train_loss : 0.53291\n",
      "current_epoch : 243, train_loss : 0.53290987\n",
      "current_epoch : 244, train_loss : 0.5329097\n",
      "current_epoch : 245, train_loss : 0.5329095\n",
      "current_epoch : 246, train_loss : 0.5329094\n",
      "current_epoch : 247, train_loss : 0.53290915\n",
      "current_epoch : 248, train_loss : 0.53290904\n",
      "current_epoch : 249, train_loss : 0.5329089\n",
      "current_epoch : 250, train_loss : 0.5329088\n",
      "current_epoch : 250, train_loss : 0.532909, test_loss : 0.579078, train_auc : 0.99408, test_auc : 0.95342, test_acc : 0.89062 \n",
      "current_epoch : 251, train_loss : 0.5329086\n",
      "current_epoch : 252, train_loss : 0.5329085\n",
      "current_epoch : 253, train_loss : 0.5329083\n",
      "current_epoch : 254, train_loss : 0.5329082\n",
      "current_epoch : 255, train_loss : 0.5329081\n",
      "current_epoch : 256, train_loss : 0.5329079\n",
      "current_epoch : 257, train_loss : 0.5329077\n",
      "current_epoch : 258, train_loss : 0.5329076\n",
      "current_epoch : 259, train_loss : 0.5329075\n",
      "current_epoch : 260, train_loss : 0.53290737\n",
      "current_epoch : 260, train_loss : 0.532907, test_loss : 0.579027, train_auc : 0.99409, test_auc : 0.95343, test_acc : 0.89062 \n",
      "current_epoch : 261, train_loss : 0.5329072\n",
      "current_epoch : 262, train_loss : 0.532907\n",
      "current_epoch : 263, train_loss : 0.53290695\n",
      "current_epoch : 264, train_loss : 0.5329068\n",
      "current_epoch : 265, train_loss : 0.53290665\n",
      "current_epoch : 266, train_loss : 0.5329065\n",
      "current_epoch : 267, train_loss : 0.53290635\n",
      "current_epoch : 268, train_loss : 0.53290623\n",
      "current_epoch : 269, train_loss : 0.5329061\n",
      "current_epoch : 270, train_loss : 0.53290594\n",
      "current_epoch : 270, train_loss : 0.532906, test_loss : 0.578980, train_auc : 0.99409, test_auc : 0.95339, test_acc : 0.89062 \n",
      "current_epoch : 271, train_loss : 0.5329058\n",
      "current_epoch : 272, train_loss : 0.5329057\n",
      "current_epoch : 273, train_loss : 0.5329056\n",
      "current_epoch : 274, train_loss : 0.5329054\n",
      "current_epoch : 275, train_loss : 0.53290534\n",
      "current_epoch : 276, train_loss : 0.5329051\n",
      "current_epoch : 277, train_loss : 0.532905\n",
      "current_epoch : 278, train_loss : 0.5329049\n",
      "current_epoch : 279, train_loss : 0.53290474\n",
      "current_epoch : 280, train_loss : 0.5329046\n",
      "current_epoch : 280, train_loss : 0.532905, test_loss : 0.578936, train_auc : 0.99409, test_auc : 0.95339, test_acc : 0.89062 \n",
      "current_epoch : 281, train_loss : 0.5329045\n",
      "current_epoch : 282, train_loss : 0.5329044\n",
      "current_epoch : 283, train_loss : 0.53290427\n",
      "current_epoch : 284, train_loss : 0.5329041\n",
      "current_epoch : 285, train_loss : 0.53290397\n",
      "current_epoch : 286, train_loss : 0.53290385\n",
      "current_epoch : 287, train_loss : 0.53290373\n",
      "current_epoch : 288, train_loss : 0.5329036\n",
      "current_epoch : 289, train_loss : 0.53290343\n",
      "current_epoch : 290, train_loss : 0.5329033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_epoch : 290, train_loss : 0.532903, test_loss : 0.578894, train_auc : 0.99410, test_auc : 0.95334, test_acc : 0.89062 \n",
      "current_epoch : 291, train_loss : 0.5329032\n",
      "current_epoch : 292, train_loss : 0.5329031\n",
      "current_epoch : 293, train_loss : 0.53290296\n",
      "current_epoch : 294, train_loss : 0.53290284\n",
      "current_epoch : 295, train_loss : 0.5329027\n",
      "current_epoch : 296, train_loss : 0.5329026\n",
      "current_epoch : 297, train_loss : 0.5329025\n",
      "current_epoch : 298, train_loss : 0.53290236\n",
      "current_epoch : 299, train_loss : 0.53290224\n",
      "current_epoch : 300, train_loss : 0.5329021\n",
      "current_epoch : 300, train_loss : 0.532902, test_loss : 0.578856, train_auc : 0.99410, test_auc : 0.95336, test_acc : 0.89160 \n",
      "current_epoch : 301, train_loss : 0.532902\n",
      "current_epoch : 302, train_loss : 0.5329019\n",
      "current_epoch : 303, train_loss : 0.53290176\n",
      "current_epoch : 304, train_loss : 0.53290164\n",
      "current_epoch : 305, train_loss : 0.5329015\n",
      "current_epoch : 306, train_loss : 0.5329014\n",
      "current_epoch : 307, train_loss : 0.5329013\n",
      "current_epoch : 308, train_loss : 0.53290117\n",
      "current_epoch : 309, train_loss : 0.53290105\n",
      "current_epoch : 310, train_loss : 0.5329009\n",
      "current_epoch : 310, train_loss : 0.532901, test_loss : 0.578820, train_auc : 0.99410, test_auc : 0.95334, test_acc : 0.89160 \n",
      "current_epoch : 311, train_loss : 0.5329008\n",
      "current_epoch : 312, train_loss : 0.5329007\n",
      "current_epoch : 313, train_loss : 0.5329006\n",
      "current_epoch : 314, train_loss : 0.53290045\n",
      "current_epoch : 315, train_loss : 0.53290033\n",
      "current_epoch : 316, train_loss : 0.5329002\n",
      "current_epoch : 317, train_loss : 0.5329001\n",
      "current_epoch : 318, train_loss : 0.5329\n",
      "current_epoch : 319, train_loss : 0.53289986\n",
      "current_epoch : 320, train_loss : 0.53289974\n",
      "current_epoch : 320, train_loss : 0.532900, test_loss : 0.578785, train_auc : 0.99409, test_auc : 0.95325, test_acc : 0.89258 \n",
      "current_epoch : 321, train_loss : 0.5328996\n",
      "current_epoch : 322, train_loss : 0.5328995\n",
      "current_epoch : 323, train_loss : 0.53289944\n",
      "current_epoch : 324, train_loss : 0.5328993\n",
      "current_epoch : 325, train_loss : 0.53289914\n",
      "current_epoch : 326, train_loss : 0.5328991\n",
      "current_epoch : 327, train_loss : 0.53289896\n",
      "current_epoch : 328, train_loss : 0.53289884\n",
      "current_epoch : 329, train_loss : 0.5328987\n",
      "current_epoch : 330, train_loss : 0.5328986\n",
      "current_epoch : 330, train_loss : 0.532899, test_loss : 0.578759, train_auc : 0.99409, test_auc : 0.95326, test_acc : 0.89258 \n",
      "current_epoch : 331, train_loss : 0.53289855\n",
      "current_epoch : 332, train_loss : 0.53289837\n",
      "current_epoch : 333, train_loss : 0.5328983\n",
      "current_epoch : 334, train_loss : 0.5328982\n",
      "current_epoch : 335, train_loss : 0.53289807\n",
      "current_epoch : 336, train_loss : 0.53289795\n",
      "current_epoch : 337, train_loss : 0.53289783\n",
      "current_epoch : 338, train_loss : 0.5328977\n",
      "current_epoch : 339, train_loss : 0.5328976\n",
      "current_epoch : 340, train_loss : 0.5328975\n",
      "current_epoch : 340, train_loss : 0.532897, test_loss : 0.578739, train_auc : 0.99409, test_auc : 0.95322, test_acc : 0.89258 \n",
      "current_epoch : 341, train_loss : 0.53289735\n",
      "current_epoch : 342, train_loss : 0.53289723\n",
      "current_epoch : 343, train_loss : 0.5328971\n",
      "current_epoch : 344, train_loss : 0.53289706\n",
      "current_epoch : 345, train_loss : 0.5328969\n",
      "current_epoch : 346, train_loss : 0.5328968\n",
      "current_epoch : 347, train_loss : 0.53289664\n",
      "current_epoch : 348, train_loss : 0.5328965\n",
      "current_epoch : 349, train_loss : 0.5328964\n",
      "current_epoch : 350, train_loss : 0.53289634\n",
      "current_epoch : 350, train_loss : 0.532896, test_loss : 0.578736, train_auc : 0.99409, test_auc : 0.95321, test_acc : 0.89355 \n",
      "current_epoch : 351, train_loss : 0.53289616\n",
      "current_epoch : 352, train_loss : 0.53289604\n",
      "current_epoch : 353, train_loss : 0.5328959\n",
      "current_epoch : 354, train_loss : 0.5328958\n",
      "current_epoch : 355, train_loss : 0.5328957\n",
      "current_epoch : 356, train_loss : 0.53289557\n",
      "current_epoch : 357, train_loss : 0.5328954\n",
      "current_epoch : 358, train_loss : 0.53289527\n",
      "current_epoch : 359, train_loss : 0.5328951\n",
      "current_epoch : 360, train_loss : 0.53289497\n",
      "current_epoch : 360, train_loss : 0.532895, test_loss : 0.578767, train_auc : 0.99410, test_auc : 0.95301, test_acc : 0.89355 \n",
      "current_epoch : 361, train_loss : 0.53289485\n",
      "current_epoch : 362, train_loss : 0.5328946\n",
      "current_epoch : 363, train_loss : 0.5328945\n",
      "current_epoch : 364, train_loss : 0.53289425\n",
      "current_epoch : 365, train_loss : 0.532894\n",
      "current_epoch : 366, train_loss : 0.5328938\n",
      "current_epoch : 367, train_loss : 0.53289354\n",
      "current_epoch : 368, train_loss : 0.53289324\n",
      "current_epoch : 369, train_loss : 0.53289294\n",
      "current_epoch : 370, train_loss : 0.5328925\n",
      "current_epoch : 370, train_loss : 0.532893, test_loss : 0.578933, train_auc : 0.99411, test_auc : 0.95294, test_acc : 0.89355 \n",
      "current_epoch : 371, train_loss : 0.53289205\n",
      "current_epoch : 372, train_loss : 0.5328914\n",
      "current_epoch : 373, train_loss : 0.5328905\n",
      "current_epoch : 374, train_loss : 0.53288937\n",
      "current_epoch : 375, train_loss : 0.5328874\n",
      "current_epoch : 376, train_loss : 0.5328841\n",
      "current_epoch : 377, train_loss : 0.53287774\n",
      "current_epoch : 378, train_loss : 0.53286433\n",
      "current_epoch : 379, train_loss : 0.5328435\n",
      "current_epoch : 380, train_loss : 0.53282976\n",
      "current_epoch : 380, train_loss : 0.532830, test_loss : 0.579608, train_auc : 0.99426, test_auc : 0.95278, test_acc : 0.89551 \n",
      "current_epoch : 381, train_loss : 0.5328237\n",
      "current_epoch : 382, train_loss : 0.5328201\n",
      "current_epoch : 383, train_loss : 0.5328173\n",
      "current_epoch : 384, train_loss : 0.5328154\n",
      "current_epoch : 385, train_loss : 0.532814\n",
      "current_epoch : 386, train_loss : 0.5328131\n",
      "current_epoch : 387, train_loss : 0.53281224\n",
      "current_epoch : 388, train_loss : 0.53281164\n",
      "current_epoch : 389, train_loss : 0.53281105\n",
      "current_epoch : 390, train_loss : 0.53281057\n",
      "current_epoch : 390, train_loss : 0.532811, test_loss : 0.579105, train_auc : 0.99422, test_auc : 0.95249, test_acc : 0.89258 \n",
      "current_epoch : 391, train_loss : 0.53281003\n",
      "current_epoch : 392, train_loss : 0.5328096\n",
      "current_epoch : 393, train_loss : 0.5328092\n",
      "current_epoch : 394, train_loss : 0.5328089\n",
      "current_epoch : 395, train_loss : 0.53280854\n",
      "current_epoch : 396, train_loss : 0.5328082\n",
      "current_epoch : 397, train_loss : 0.5328078\n",
      "current_epoch : 398, train_loss : 0.5328076\n",
      "current_epoch : 399, train_loss : 0.53280723\n",
      "current_epoch : 400, train_loss : 0.532807\n",
      "current_epoch : 400, train_loss : 0.532807, test_loss : 0.579098, train_auc : 0.99421, test_auc : 0.95245, test_acc : 0.89355 \n",
      "current_epoch : 401, train_loss : 0.5328067\n",
      "current_epoch : 402, train_loss : 0.5328064\n",
      "current_epoch : 403, train_loss : 0.53280616\n",
      "current_epoch : 404, train_loss : 0.532806\n",
      "current_epoch : 405, train_loss : 0.53280574\n",
      "current_epoch : 406, train_loss : 0.53280544\n",
      "current_epoch : 407, train_loss : 0.53280526\n",
      "current_epoch : 408, train_loss : 0.5328051\n",
      "current_epoch : 409, train_loss : 0.53280485\n",
      "current_epoch : 410, train_loss : 0.5328046\n",
      "current_epoch : 410, train_loss : 0.532805, test_loss : 0.579119, train_auc : 0.99420, test_auc : 0.95209, test_acc : 0.89258 \n",
      "current_epoch : 411, train_loss : 0.5328045\n",
      "current_epoch : 412, train_loss : 0.53280425\n",
      "current_epoch : 413, train_loss : 0.532804\n",
      "current_epoch : 414, train_loss : 0.5328039\n",
      "current_epoch : 415, train_loss : 0.53280365\n",
      "current_epoch : 416, train_loss : 0.53280354\n",
      "current_epoch : 417, train_loss : 0.53280336\n",
      "current_epoch : 418, train_loss : 0.5328032\n",
      "current_epoch : 419, train_loss : 0.53280306\n",
      "current_epoch : 420, train_loss : 0.5328028\n",
      "current_epoch : 420, train_loss : 0.532803, test_loss : 0.579131, train_auc : 0.99419, test_auc : 0.95220, test_acc : 0.89258 \n",
      "current_epoch : 421, train_loss : 0.5328027\n",
      "current_epoch : 422, train_loss : 0.5328026\n",
      "current_epoch : 423, train_loss : 0.53280234\n",
      "current_epoch : 424, train_loss : 0.5328022\n",
      "current_epoch : 425, train_loss : 0.5328021\n",
      "current_epoch : 426, train_loss : 0.5328019\n",
      "current_epoch : 427, train_loss : 0.5328018\n",
      "current_epoch : 428, train_loss : 0.5328016\n",
      "current_epoch : 429, train_loss : 0.5328015\n",
      "current_epoch : 430, train_loss : 0.5328014\n",
      "current_epoch : 430, train_loss : 0.532801, test_loss : 0.579135, train_auc : 0.99419, test_auc : 0.95171, test_acc : 0.89258 \n",
      "current_epoch : 431, train_loss : 0.5328012\n",
      "current_epoch : 432, train_loss : 0.5328011\n",
      "current_epoch : 433, train_loss : 0.532801\n",
      "current_epoch : 434, train_loss : 0.5328008\n",
      "current_epoch : 435, train_loss : 0.5328007\n",
      "current_epoch : 436, train_loss : 0.5328006\n",
      "current_epoch : 437, train_loss : 0.53280044\n",
      "current_epoch : 438, train_loss : 0.5328003\n",
      "current_epoch : 439, train_loss : 0.5328002\n",
      "current_epoch : 440, train_loss : 0.5328001\n",
      "current_epoch : 440, train_loss : 0.532800, test_loss : 0.579128, train_auc : 0.99409, test_auc : 0.95169, test_acc : 0.89258 \n",
      "current_epoch : 441, train_loss : 0.53279996\n",
      "current_epoch : 442, train_loss : 0.53279984\n",
      "current_epoch : 443, train_loss : 0.5327997\n",
      "current_epoch : 444, train_loss : 0.5327996\n",
      "current_epoch : 445, train_loss : 0.5327995\n",
      "current_epoch : 446, train_loss : 0.53279936\n",
      "current_epoch : 447, train_loss : 0.53279924\n",
      "current_epoch : 448, train_loss : 0.5327992\n",
      "current_epoch : 449, train_loss : 0.53279907\n",
      "current_epoch : 450, train_loss : 0.5327989\n",
      "current_epoch : 450, train_loss : 0.532799, test_loss : 0.579117, train_auc : 0.99409, test_auc : 0.95177, test_acc : 0.89258 \n",
      "current_epoch : 451, train_loss : 0.5327988\n",
      "current_epoch : 452, train_loss : 0.5327987\n",
      "current_epoch : 453, train_loss : 0.53279865\n",
      "current_epoch : 454, train_loss : 0.5327985\n",
      "current_epoch : 455, train_loss : 0.5327984\n",
      "current_epoch : 456, train_loss : 0.5327983\n",
      "current_epoch : 457, train_loss : 0.53279823\n",
      "current_epoch : 458, train_loss : 0.5327981\n",
      "current_epoch : 459, train_loss : 0.532798\n",
      "current_epoch : 460, train_loss : 0.53279793\n",
      "current_epoch : 460, train_loss : 0.532798, test_loss : 0.579104, train_auc : 0.99408, test_auc : 0.95182, test_acc : 0.89258 \n",
      "current_epoch : 461, train_loss : 0.5327978\n",
      "current_epoch : 462, train_loss : 0.53279775\n",
      "current_epoch : 463, train_loss : 0.5327977\n",
      "current_epoch : 464, train_loss : 0.5327976\n",
      "current_epoch : 465, train_loss : 0.53279746\n",
      "current_epoch : 466, train_loss : 0.53279734\n",
      "current_epoch : 467, train_loss : 0.5327973\n",
      "current_epoch : 468, train_loss : 0.53279716\n",
      "current_epoch : 469, train_loss : 0.5327971\n",
      "current_epoch : 470, train_loss : 0.532797\n",
      "current_epoch : 470, train_loss : 0.532797, test_loss : 0.579089, train_auc : 0.99408, test_auc : 0.95175, test_acc : 0.89258 \n",
      "current_epoch : 471, train_loss : 0.5327969\n",
      "current_epoch : 472, train_loss : 0.53279674\n",
      "current_epoch : 473, train_loss : 0.53279674\n",
      "current_epoch : 474, train_loss : 0.5327966\n",
      "current_epoch : 475, train_loss : 0.5327965\n",
      "current_epoch : 476, train_loss : 0.53279644\n",
      "current_epoch : 477, train_loss : 0.5327964\n",
      "current_epoch : 478, train_loss : 0.53279626\n",
      "current_epoch : 479, train_loss : 0.5327962\n",
      "current_epoch : 480, train_loss : 0.5327961\n",
      "current_epoch : 480, train_loss : 0.532796, test_loss : 0.579073, train_auc : 0.99386, test_auc : 0.95175, test_acc : 0.89258 \n",
      "current_epoch : 481, train_loss : 0.532796\n",
      "current_epoch : 482, train_loss : 0.5327959\n",
      "current_epoch : 483, train_loss : 0.53279585\n",
      "current_epoch : 484, train_loss : 0.5327957\n",
      "current_epoch : 485, train_loss : 0.53279567\n",
      "current_epoch : 486, train_loss : 0.53279555\n",
      "current_epoch : 487, train_loss : 0.53279555\n",
      "current_epoch : 488, train_loss : 0.5327954\n",
      "current_epoch : 489, train_loss : 0.53279537\n",
      "current_epoch : 490, train_loss : 0.5327953\n",
      "current_epoch : 490, train_loss : 0.532795, test_loss : 0.579058, train_auc : 0.99387, test_auc : 0.95178, test_acc : 0.89258 \n",
      "current_epoch : 491, train_loss : 0.5327952\n",
      "current_epoch : 492, train_loss : 0.5327951\n",
      "current_epoch : 493, train_loss : 0.532795\n",
      "current_epoch : 494, train_loss : 0.53279495\n",
      "current_epoch : 495, train_loss : 0.5327949\n",
      "current_epoch : 496, train_loss : 0.53279483\n",
      "current_epoch : 497, train_loss : 0.5327947\n",
      "current_epoch : 498, train_loss : 0.53279465\n",
      "current_epoch : 499, train_loss : 0.5327946\n",
      "current_epoch : 500, train_loss : 0.5327945\n",
      "current_epoch : 500, train_loss : 0.532794, test_loss : 0.579045, train_auc : 0.99387, test_auc : 0.95178, test_acc : 0.89258 \n",
      "Wall time: 36min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_each_iter = 10\n",
    "train_epoch = 501\n",
    "batch_size = 256\n",
    "learning_rate = 0.0001\n",
    "batch_per_epoch_train = X_train.shape[0] // batch_size\n",
    "batch_per_epoch_test = X_test.shape[0] // batch_size\n",
    "\n",
    "if batch_per_epoch_train < 1 : batch_per_epoch_train = 1\n",
    "if batch_per_epoch_test < 1 : batch_per_epoch_test = 1\n",
    "\n",
    "\n",
    "for current_epoch in range(train_epoch) :\n",
    "    \n",
    "    train_loss = []\n",
    "    train_auc = []\n",
    "    for batch_indx in range(batch_per_epoch_train) :    \n",
    "        X_train_batch,y_train_batch,seq_length = get_next_batch(X_train,y_train,batch_size,batch_indx)\n",
    "        \n",
    "        _,tr_loss = sess.run([optimizer,loss],feed_dict={input_vect : X_train_batch,\n",
    "                                                         input_y : y_train_batch,\n",
    "                                                         sequence_length : seq_length,\n",
    "                                                         lr : learning_rate})\n",
    "        train_loss.append(tr_loss)\n",
    "        #check train auc\n",
    "        if current_epoch % test_each_iter == 0 :\n",
    "            pred_train = sess.run(logits,feed_dict={input_vect:X_train_batch, \n",
    "                                                    input_y:y_train_batch,\n",
    "                                                    sequence_length : seq_length})            \n",
    "            auc = roc_auc_score(y_train_batch,pred_train)\n",
    "            train_auc.append(auc)        \n",
    "            \n",
    "    train_loss = np.average(train_loss)\n",
    "    train_auc = np.average(train_auc)\n",
    "    print('current_epoch : %s, train_loss : %s' % (current_epoch,train_loss))\n",
    "    \n",
    "    \n",
    "    #testing\n",
    "    if current_epoch % test_each_iter == 0 :\n",
    "        test_loss = []\n",
    "        test_acc = []\n",
    "        test_auc = []\n",
    "        \n",
    "        for batch_indx in range(batch_per_epoch_test) :\n",
    "            X_test_batch,y_test_batch,seq_length = get_next_batch(X_test,y_test,batch_size,batch_indx)\n",
    "            \n",
    "            #loss\n",
    "            ts_loss = sess.run(loss,feed_dict={input_vect:X_test_batch, \n",
    "                                               input_y : y_test_batch,\n",
    "                                              sequence_length : seq_length})\n",
    "            test_loss.append(ts_loss)\n",
    "            \n",
    "            #acc\n",
    "            pred_test = sess.run(logits,feed_dict={input_vect:X_test_batch, \n",
    "                                                   input_y:y_test_batch,\n",
    "                                                   sequence_length : seq_length})\n",
    "            acc_test = np.average((pred_test > 0.5) == y_test_batch)\n",
    "            test_acc.append(acc_test)\n",
    "\n",
    "            #aucroc\n",
    "            auc = roc_auc_score(y_test_batch,pred_test)\n",
    "            test_auc.append(auc)\n",
    "        \n",
    "        test_loss = np.average(test_loss)\n",
    "        test_acc = np.average(test_acc)\n",
    "        test_auc = np.average(test_auc)\n",
    "        print('current_epoch : %s, train_loss : %.6f, test_loss : %.6f, train_auc : %.5f, test_auc : %.5f, test_acc : %.5f ' % \\\n",
    "              (current_epoch,train_loss,test_loss,train_auc,test_auc,test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Honest test acc : 0.8931159420289855 \n",
      "Honest test auc : : 0.9539141082111628 \n"
     ]
    }
   ],
   "source": [
    "#eval honest test accuracy : \n",
    "seq_lengh = get_seq_len(X_test)\n",
    "\n",
    "pred_test = sess.run(logits,feed_dict={input_vect:X_test, input_y:y_test , sequence_length:seq_lengh}) \n",
    "honest_test_acc = np.average((pred_test > 0.5) == y_test)\n",
    "print('Honest test acc : %s ' % honest_test_acc)\n",
    "\n",
    "\n",
    "#eval honest test auc (over 2d class): \n",
    "honest_test_auc = roc_auc_score(y_test,pred_test)\n",
    "print('Honest test auc : : %s ' % honest_test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stuped prediction accuracy over all dataset : 0.574121058354 \n",
      "Stuped prediction accuracy over test : 0.584239130435 \n"
     ]
    }
   ],
   "source": [
    "#stuped prediction\n",
    "Y_stuped = np.zeros(Y.shape)\n",
    "Y_stuped[:,0] = 1\n",
    "\n",
    "Y_stuped_test = np.zeros(y_test.shape)\n",
    "Y_stuped_test[:,0] = 1\n",
    "\n",
    "print('Stuped prediction accuracy over all dataset : %s ' %np.average(Y == Y_stuped))\n",
    "print('Stuped prediction accuracy over test : %s ' % np.average(y_test == Y_stuped_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is D\n",
      " Volume Serial Number is E211-0876\n",
      "\n",
      " Directory of D:\\Programing\\00_ipython_projects\\CS224 Deep Learning with NLP. IPavlov\\project\n",
      "\n",
      "10-Apr-18  20:17    <DIR>          .\n",
      "10-Apr-18  20:17    <DIR>          ..\n",
      "03-Apr-18  16:45    <DIR>          .ipynb_checkpoints\n",
      "10-Apr-18  20:17           119,743 baseline with InferSent _ smart user split.ipynb\n",
      "03-Apr-18  16:44            63,644 baseline with InferSent.ipynb\n",
      "28-Mar-18  21:05            14,888 baseline.ipynb\n",
      "10-Apr-18  20:11    <DIR>          data\n",
      "27-Mar-18  20:37            12,997 explore data.ipynb\n",
      "30-Mar-18  14:20    <DIR>          InferSent\n",
      "30-Mar-18  13:52            33,674 models.py\n",
      "09-Apr-18  19:11    <DIR>          tmp\n",
      "30-Mar-18  14:18    <DIR>          __pycache__\n",
      "               5 File(s)        244,946 bytes\n",
      "               7 Dir(s)  505,381,924,864 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path: model/lstm32d64_c_seql_paddzer_lr3_200_lr4_500.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Save the variables to disk.\n",
    "MODEL_NAME = 'lstm32d64_c_seql_paddzer_lr3_200_lr4_500'\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(sess, MODEL_PATH + MODEL_NAME + '.ckpt')\n",
    "print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand lstm output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test out\n",
    "lstm_outputs_arr,flatten_arr,states_list = sess.run([lstm_outputs,flatten,states],\n",
    "                                                    feed_dict = {input_vect : X_train_batch, input_y : y_train_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm_outputs_arr shape : (256, 34, 512)\n",
      "flatten_arr shape (256, 17408)\n",
      "Sum over all lstm out : -4359.21\n",
      "Sum over all lstm c : (256, 512) \n",
      "Sum over all lstm h : (256, 512) \n"
     ]
    }
   ],
   "source": [
    "print('lstm_outputs_arr shape : %s' % str(lstm_outputs_arr.shape))\n",
    "print('flatten_arr shape %s' % str(flatten_arr.shape))\n",
    "\n",
    "print('Sum over all lstm out : %s' % lstm_outputs_arr.sum())\n",
    "print('Sum over all lstm c : %s ' % str(states_list.c.shape))\n",
    "print('Sum over all lstm h : %s ' % str(states_list.h.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.996468\n"
     ]
    }
   ],
   "source": [
    "print(states_list.h[0].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
